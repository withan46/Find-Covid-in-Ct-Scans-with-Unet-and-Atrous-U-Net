# -*- coding: utf-8 -*-
"""Athanasios Emmanouilidis Atrous Code

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_MwSO3sUfdwOgdMvd3H18Jc2sQzJ-UGJ
"""

#import data from drive
from google.colab import drive
drive.mount('/content/drive')

# Import necessary libraries
import zipfile
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import cv2
from sklearn.model_selection import train_test_split, KFold
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, CSVLogger
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, UpSampling2D, BatchNormalization, Activation, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.metrics import MeanIoU
from tensorflow.keras.optimizers import Adam
from skimage.restoration import denoise_nl_means, estimate_sigma
import nibabel as nib
import gc
import tensorflow.keras.backend as K
from skimage import filters, io
from tensorflow.keras.regularizers import l2
from tensorflow.keras.metrics import Precision, Recall
from tensorflow.keras.backend import flatten, sum
from keras.losses import binary_crossentropy

# Unzip the dataset
zip_ref = zipfile.ZipFile('/content/drive/MyDrive/Colab Notebooks/archive.zip', 'r')
zip_ref.extractall('../input/covid19-ct-scans')
zip_ref.close()

# Prepare the data and split it
data = pd.read_csv('../input/covid19-ct-scans/metadata.csv')
data.head()

def calculate_noise(image_slice):
    """Calculate the noise level in the image slice using standard deviation."""
    return np.std(image_slice)

def apply_non_local_means(image, h=10, template_window_size=7, search_window_size=21):
    return cv2.fastNlMeansDenoising(image, None, h, template_window_size, search_window_size)

def read_nii(filepath, type_of_image, index, img_size=512):
    desire_size = 256
    ct_scan = nib.load(filepath)
    array = np.rot90(np.array(ct_scan.get_fdata()))
    slices = array.shape[2]
    array = array[:, :, round(slices * 0.2):round(slices * 0.8)]
    array = np.reshape(np.rollaxis(array, 2), (array.shape[2], array.shape[0], array.shape[1], 1))
    processed_imgs = []

    # Ensure array is not empty
    if array.size == 0:
        raise ValueError("Loaded image data is empty.")

    # Load and process lung and infection masks
    lung_scan = nib.load(data.loc[index, 'lung_mask'])
    lung_mask = np.rot90(np.array(lung_scan.get_fdata()))
    lung_mask = lung_mask[:, :, round(slices * 0.2):round(slices * 0.8)]
    lung_mask = np.rollaxis(lung_mask, 2)

    infection = nib.load(data.loc[index, 'infection_mask'])
    infection_mask = np.rot90(np.array(infection.get_fdata()))
    infection_mask = infection_mask[:, :, round(slices * 0.2):round(slices * 0.8)]
    infection_mask = np.rollaxis(infection_mask, 2)

    for img_no in range(array.shape[0]):
        img = cv2.resize(array[img_no], dsize=(img_size, img_size), interpolation=cv2.INTER_AREA)
        lung_mask_resized = cv2.resize(lung_mask[img_no], dsize=(img_size, img_size), interpolation=cv2.INTER_NEAREST)

        # Ensure the image is in 8-bit format before thresholding
        lung_mask_resized = cv2.normalize(lung_mask_resized, None, 0, 255, cv2.NORM_MINMAX)  # Normalize the mask to 0-255
        lung_mask_resized = lung_mask_resized.astype(np.uint8)  # Convert to unsigned 8-bit integer

        # Now apply threshold with OTSU
        _, binary_mask = cv2.threshold(lung_mask_resized, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)


        # Normalization
        xmax, xmin = img.max(), img.min()
        img = (img - xmin) / (xmax - xmin)


        # _, binary_mask = cv2.threshold(lung_mask[img_no], 0, 255, cv2.THRESH_BINARY)
        # contours, _ = cv2.findContours(binary_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # CLAHE
        if type_of_image == 'ct_scan':
          img_8bit = np.uint8(img * 255)
          clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(32,32))
          clahe_img = clahe.apply(img_8bit)

          # Gamma Correction
          gamma = 1.2
          img = np.array(255 * (clahe_img / 255) ** gamma, dtype='uint8')

          # plt.imshow(img, cmap='gray')
          # plt.title('CT Scan')
          # plt.axis('off')
          # plt.show()

        # if type_of_image == 'infection_mask':
        #   plt.imshow(img, cmap='gray')
        #   plt.title('Infection Mask')
        #   plt.axis('off')
        #   plt.show()

        # Ensure overlay and lung_mask are the same size before creating mask_overlay
        # overlay = img.squeeze().copy()
        # lung_mask_resized = cv2.resize(lung_mask[img_no], (img_size, img_size), interpolation=cv2.INTER_NEAREST).squeeze()

        # mask_overlay = np.zeros_like(overlay)
        # mask_overlay[lung_mask_resized > 0] = 1  # Apply resized mask

        # plt.imshow(overlay, cmap='gray')
        # plt.imshow(mask_overlay, cmap='jet', alpha=0.5)  # Show overlay with mask
        # plt.axis('off')
        # plt.show()

        debug_img = img.copy()
        for contour in contours:
            cv2.drawContours(debug_img, [contour], -1, (0, 255, 0), 2)  # Draw contours in green

        if contours:
          padding = 2

          # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

          # for contour in contours:
          #   x, y, w, h = cv2.boundingRect(contour)
          #   cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)  # Draw in red

          # plt.imshow(img, cmap='gray')
          # plt.title("Debug: Contours and Bounding Boxes")
          # plt.axis('off')
          # plt.show()

          # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

          if len(contours) > 1:

            # Υπολογισμός του ορθογωνίου περιβλήματος για το περίγραμμα με δείκτη 0
            x1, y1, w1, h1 = cv2.boundingRect(contours[0])
            min_x1 = max(0, x1 - padding)
            min_y1 = max(0, y1 - padding)
            max_x1 = min(img.shape[1], x1 + w1 + padding)
            max_y1 = min(img.shape[0], y1 + h1 + padding)

            # print("%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%")
            # print(max_x1 - min_x1, max_y1 - min_y1)
            # print("%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%")

            # Υπολογισμός του ορθογωνίου περιβλήματος για το περίγραμμα με δείκτη 1
            x2, y2, w2, h2 = cv2.boundingRect(contours[1])
            min_x2 = max(0, x2 - padding)
            min_y2 = max(0, y2 - padding)
            max_x2 = min(img.shape[1], x2 + w2 + padding)
            max_y2 = min(img.shape[0], y2 + h2 + padding)

            # print("%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%")
            # print(max_x2 - min_x2, max_y2 - min_y2)
            # print("%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%")

            if max_x1 - min_x1 > 87 and max_y1 - min_y1 > 62 and max_x2 - min_x2 > 87 and max_y2 - min_y2 > 62:
              # Περικοπή της εικόνας για το πρώτο περίγραμμα
              cropped_image1 = img[min_y1:max_y1, min_x1:max_x1]

              # Περικοπή της εικόνας για το δεύτερο περίγραμμα
              cropped_image2 = img[min_y2:max_y2, min_x2:max_x2]

              # Εύρεση του μεγαλύτερου width και height
              max_width = max(cropped_image1.shape[1], cropped_image2.shape[1])
              max_height = max(cropped_image1.shape[0], cropped_image2.shape[0])

              # # Ανάλογα resize των εικόνων ώστε να έχουν το ίδιο ύψος
              if min_x1 < max_x1 and min_y1 < max_y1 and min_x2 < max_x2 and min_y2 < max_y2:
                # # Προσθήκη padding για κεντράρισμα
                # resized_crop1 = resize_image_to_max_dimensions(cropped_image1, desire_size)
                # final_crop1 = add_black_border(resized_crop1, desire_size, desire_size)

                # # Παράδειγμα προσαρμογής για την εικόνα crop2
                # resized_crop2 = resize_image_to_max_dimensions(cropped_image2, desire_size)
                # final_crop2 = add_black_border(resized_crop2, desire_size, desire_size)

                final_crop1 = cv2.resize(cropped_image1, (desire_size, desire_size), interpolation=cv2.INTER_LINEAR)
                final_crop2 = cv2.resize(cropped_image2, (desire_size, desire_size), interpolation=cv2.INTER_LINEAR)

                if final_crop1.size > 0 and final_crop2.size > 0:
                  # Ένωση των δύο εικόνων κατά μήκος της διάστασης πλάτους (axis=1)
                  cropped_image = np.hstack((final_crop1, final_crop2))

                  processed_imgs.append(cv2.resize(cropped_image, (desire_size, desire_size)))
                  # plt.imshow(cropped_image, cmap='gray')
                  # plt.title('Cropped Images')
                  # plt.axis('off')
                  # plt.show()

                # if index >= 8 and img_no < 3 :
                #     # Display original image with contours
                #     plt.imshow(debug_img, cmap='gray')
                #     plt.title(f'Original CT Scan with Contours (Slice {img_no})')
                #     plt.axis('off')
                #     plt.show()

                #     # Display cropped regions
                #     plt.imshow(cropped_image1, cmap='gray')
                #     plt.title(f'Cropped Region 1 (Slice {img_no})')
                #     plt.axis('off')
                #     plt.show()

                #     plt.imshow(cropped_image2, cmap='gray')
                #     plt.title(f'Cropped Region 2 (Slice {img_no})')
                #     plt.axis('off')
                #     plt.show()

                #     # Display final cropped image
                #     plt.imshow(cropped_image, cmap='gray')
                #     plt.title(f'Cropped CT Scan (Slice {img_no})')
                #     plt.axis('off')
                #     plt.show()

              else:
                print("Invalid crop dimension")
            elif max_x1 - min_x1 > 87 and max_y1 - min_y1 > 62 or max_x2 - min_x2 > 87 and max_y2 - min_y2 > 62:
              # Περικοπή της εικόνας για το πρώτο περίγραμμα
              if max_x1 - min_x1 > 87 and max_y1 - min_y1 > 62:
                cropped_image = img[min_y1:max_y1, min_x1:max_x1]

              # Περικοπή της εικόνας για το δεύτερο περίγραμμα
              if max_x2 - min_x2 > 87 and max_y2 - min_y2 > 62:
                cropped_image = img[min_y2:max_y2, min_x2:max_x2]

              # Εύρεση του μεγαλύτερου width και height
              max_width = cropped_image.shape[1]
              max_height = cropped_image.shape[0]

              # # Ανάλογα resize των εικόνων ώστε να έχουν το ίδιο ύψος
              if min_x1 < max_x1 and min_y1 < max_y1 or min_x2 < max_x2 and min_y2 < max_y2:
                # # Προσθήκη padding για κεντράρισμα
                # resized_crop1 = resize_image_to_max_dimensions(cropped_image1, desire_size)
                # final_crop1 = add_black_border(resized_crop1, desire_size, desire_size)

                # # Παράδειγμα προσαρμογής για την εικόνα crop2
                # resized_crop2 = resize_image_to_max_dimensions(cropped_image2, desire_size)
                # final_crop2 = add_black_border(resized_crop2, desire_size, desire_size)

                final_crop1 = cv2.resize(cropped_image, (desire_size, desire_size), interpolation=cv2.INTER_LINEAR)

                if final_crop1.size > 0:
                  # Ένωση των δύο εικόνων κατά μήκος της διάστασης πλάτους (axis=1)
                  processed_imgs.append(final_crop1)

                  # if index >= 8 and img_no < 3 :
                  #   # Display original image with contours
                  #   plt.imshow(debug_img, cmap='gray')
                  #   plt.title(f'Original CT Scan with Contours (Slice {img_no})')
                  #   plt.axis('off')
                  #   plt.show()

                  #   # Display cropped region
                  #   plt.imshow(final_crop1, cmap='gray')
                  #   plt.title(f'Cropped Region (Slice {img_no})')
                  #   plt.axis('off')
                  #   plt.show()

                  #   # Display final cropped image
                  #   plt.imshow(final_crop1, cmap='gray')
                  #   plt.title(f'Cropped CT Scan (Slice {img_no})')
                  #   plt.axis('off')
                  #   plt.show()

                  # plt.imshow(final_crop1, cmap='gray')
                  # plt.title('222222222222222222222222222222222222')
                  # plt.axis('off')
                  # plt.show()
          else:            # Calculate the bounding box for all contours
            min_x = min([cv2.boundingRect(contour)[0] for contour in contours])
            max_x = max([cv2.boundingRect(contour)[0] + cv2.boundingRect(contour)[2] for contour in contours])
            min_y = min([cv2.boundingRect(contour)[1] for contour in contours])
            max_y = max([cv2.boundingRect(contour)[1] + cv2.boundingRect(contour)[3] for contour in contours])

            # Add padding for safety
            padding = 10
            min_x = max(0, min_x - padding)
            min_y = max(0, min_y - padding)
            max_x = min(img.shape[1], max_x + padding)
            max_y = min(img.shape[0], max_y + padding)

            cropped_image = img[min_y:max_y, min_x:max_x]

            noise_level = calculate_noise(cropped_image)

            if type_of_image == 'ct_scan':
              cropped_image = apply_non_local_means(cropped_image)



            # plt.imshow(cropped_image, cmap='gray')
            # plt.title('One Image')
            # plt.axis('off')
            # plt.show()

            processed_imgs.append(cv2.resize(cropped_image, (desire_size, desire_size)))
        else:
          processed_imgs.append(cv2.resize(img, (desire_size, desire_size)))

    return np.array(processed_imgs)

# Prompt: Read samples
ct_scan = []
# lung_mask = []
infection_mask = []
# lung_and_infection_mask = []

for i in range(0, 20):
  # print(data.loc[i, 'lung_mask'])
  # print(type(data.loc[i, 'lung_mask']))

  # Read the first sample
  ct_scan.append(read_nii(data.loc[i, 'ct_scan'], 'ct_scan', i))

  # Read the second sample

  infection_mask.append(read_nii(data.loc[i, 'infection_mask'], 'infection_mask', i))

  # lung_mask.append(read_nii(data.loc[i, 'lung_mask'], 'lung_mask', i))

  # lung_and_infection_mask.append(read_nii(data.loc[i, 'lung_and_infection_mask'], 'lung_and_infection_mask'))

# Filtering out the arrays that are completely filled with NaNs
# filtered_infection_mask = [arr for arr in infection_mask if not np.all(np.isnan(arr))]


def is_black_or_nan(image_slice):
    """
    Ελέγχει αν η εικόνα είναι μαύρη ή περιέχει μόνο NaN.

    Παράμετροι:
    image_slice (np.ndarray): Μια δισδιάστατη εικόνα.

    Επιστρέφει:
    str: 'black' αν η εικόνα είναι μαύρη, 'nan' αν η εικόνα περιέχει μόνο NaN, 'normal' αν είναι κανονική.
    """
    if np.all(image_slice == 0):
        return 'black'
    elif np.all(np.isnan(image_slice)):
        return 'nan'
    else:
        return 'normal'

# for index in range(0,20):
#   print(ct_scan[index].shape)
#   print(infection_mask[index].shape)

def proportion_of_white_pixels(slice_data, threshold=0.95):  # Adjust the threshold as needed
    # print(f"Unique pixel values: {np.unique(slice_data)}")  # Check what unique values exist
    n_white_pix = np.sum(slice_data > threshold)  # Check for pixels greater than threshold
    total_pixels = slice_data.size
    white_pixel_proportion = n_white_pix / total_pixels
    # print(f"Number of white pixels: {n_white_pix}, Total pixels: {total_pixels}")
    # print(f"White pixel proportion: {white_pixel_proportion:.4f}")

    # # Optional: Show the image slice for visual verification
    # plt.imshow(slice_data, cmap='gray')
    # plt.title(f'Slice Proportion: {white_pixel_proportion:.2%}')
    # plt.axis('off')
    # plt.show()

    return white_pixel_proportion

for index in range(0,20):
  print(ct_scan[index].shape)
  print(infection_mask[index].shape)

print(len(infection_mask))

white_pixel_threshold = 0.005  # 0.5%

for idx in range(len(infection_mask)):
    mask = np.array(infection_mask[idx])
    ct = np.array(ct_scan[idx])
    # lg = lung_mask[idx]
    # lgand = lung_and_infection_mask[idx]

    # Λογική μάσκα για κανονικά slices
    # normal_slices = [i for i in range(mask.shape[0]) if is_black_or_nan(mask[i, :, :]) == 'normal' and calculate_noise(ct[i, :,:])<60]
    # normal_slices = [i for i in range(mask.shape[0]) if is_black_or_nan(mask[i, :, :]) == 'normal' ]
    normal_slices = [i for i in range(mask.shape[0]) if is_black_or_nan(mask[i, :, :]) == 'normal' and proportion_of_white_pixels(mask[i, :, :], 0.95) > white_pixel_threshold]
    # normal_slices = [i for i in range(mask.shape[0]) if proportion_of_white_pixels(mask[i, :, :]) < white_pixel_threshold]


    # Φιλτράρισμα in-place
    infection_mask[idx] = mask[normal_slices, :, :]
    ct_scan[idx] = ct[normal_slices, :, :]

     # Υπολογισμός θορύβου και απαλοιφή αν χρειάζεται'


    # lung_mask[idx] = lg[normal_slices, :, :]
    # lung_and_infection_mask[idx] = lgand[normal_slices, :, :]

    # Προαιρετική εμφάνιση των φιλτραρισμένων slices
    # plot_all_slices(infection_mask[idx])
    # plot_all_slices(ct_scan[idx])

for index in range(0,20):
  print(ct_scan[index].shape)
  print(infection_mask[index].shape)

# prompt: remove from ct_scan slice 0 first 9 images

  # Model training
  # history = model.fit(
  #   train_generator,
  #   validation_data=val_generator,
  #   epochs=50,
  #   callbacks=callbacks,

# Assuming ct_scan is a list of 3D numpy arrays (slices, height, width)
ct_scan[0] = ct_scan[0][9:]
infection_mask[0] = infection_mask[0][9:]

ct_scan[2] = ct_scan[2][9:]
infection_mask[2] = infection_mask[2][9:]

ct_scan[9] = ct_scan[9][9:]
infection_mask[9] = infection_mask[9][9:]

# def plot_slices_in_batches(ct_scans, infection_masks, slices_per_batch=10):
#     for scan_index, (scan, mask) in enumerate(zip(ct_scans, infection_masks)):
#       num_slices = scan.shape[0]  # Number of slices in the current scan

#       if num_slices == 0:
#           print(f"CT Scan {scan_index} has no images.")
#           continue  # Skip to the next scan if there are no slices

#       # Iterate over slices in batches
#       for batch_start in range(0, num_slices, slices_per_batch):
#           batch_end = min(batch_start + slices_per_batch, num_slices)
#           num_slices_in_batch = batch_end - batch_start

#           # Setup the figure to plot each slice for the current batch
#           fig, axes = plt.subplots(1, num_slices_in_batch, figsize=(5 * num_slices_in_batch, 5))
#           fig.suptitle(f'CT Scan {scan_index} Slices {batch_start}-{batch_end-1}', fontsize=16)

#           # Ensure axes is always iterable (important for when num_slices_in_batch is 1)
#           if num_slices_in_batch == 1:
#               axes = [axes]

#           for i, slice_index in enumerate(range(batch_start, batch_end)):
#               if scan[slice_index].size == 0:  # Check if the slice is empty
#                   print(f"Slice {slice_index} in CT Scan {scan_index} is empty.")
#                   axes[i].set_visible(False)  # Hide the subplot for empty slices
#               else:
#                   slice_data = scan[slice_index]
#                   mask_data = mask[slice_index]

#                   # Display the CT scan
#                   axes[i].imshow(slice_data, cmap='gray')

#                   # Overlay the infection mask with low opacity
#                   axes[i].imshow(mask_data, cmap='jet', alpha=0.3)  # Adjust alpha for desired transparency

#                   noise_level = proportion_of_white_pixels(slice_data)
#                   axes[i].set_title(f'Slice {slice_index}\nNoise: {noise_level:.2f}')
#                   axes[i].axis('off')

#           plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to make room for the title
#           plt.show()

# # Assuming ct_scans and infection_masks are lists where each element is a numpy array representing a CT scan and its corresponding infection mask
# plot_slices_in_batches(ct_scan, infection_mask)

# def plot_slices_in_batches(ct_scans, slices_per_batch=10):
#     for scan_index, scan in enumerate(ct_scans):
#         num_slices = scan.shape[0]  # Number of slices in the current scan

#         if num_slices == 0:
#             print(f"CT Scan {scan_index} has no images.")
#             continue  # Skip to the next scan if there are no slices

#         # Iterate over slices in batches
#         for batch_start in range(0, num_slices, slices_per_batch):
#             batch_end = min(batch_start + slices_per_batch, num_slices)
#             num_slices_in_batch = batch_end - batch_start

#             # Setup the figure to plot each slice for the current batch
#             fig, axes = plt.subplots(1, num_slices_in_batch, figsize=(5 * num_slices_in_batch, 5))
#             fig.suptitle(f'CT Scan {scan_index} Slices {batch_start}-{batch_end-1}', fontsize=16)

#             # Ensure axes is always iterable (important for when num_slices_in_batch is 1)
#             if num_slices_in_batch == 1:
#                 axes = [axes]

#             for i, slice_index in enumerate(range(batch_start, batch_end)):
#                 if scan[slice_index].size == 0:  # Check if the slice is empty
#                     print(f"Slice {slice_index} in CT Scan {scan_index} is empty.")
#                     axes[i].set_visible(False)  # Hide the subplot for empty slices
#                 else:
#                     slice_data = scan[slice_index]
#                     axes[i].imshow(slice_data, cmap='gray')
#                     white_pixels = proportion_of_white_pixels(slice_data)
#                     axes[i].set_title(f'Slice {slice_index} proportion_of_white_pixels: {white_pixels:.2f}')
#                     axes[i].axis('off')

#             plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to make room for the title
#             plt.show()
# # Assuming ct_scan is a list where each element is a numpy array representing a CT scan
# plot_slices_in_batches(ct_scan)

import tensorflow as tf

# Precision
Precision = tf.keras.metrics.Precision()

# Recall
Recall = tf.keras.metrics.Recall()

# F1 Score
def F1_score(y_true, y_pred):
    precision = Precision(y_true, y_pred)
    recall = Recall(y_true, y_pred)
    f1 = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())
    return f1

def dice_coeff(y_true, y_pred, smooth=1):
    y_true_f = flatten(tf.cast(y_true, tf.float32))  # Cast to float32
    y_pred_f = flatten(tf.cast(y_pred, tf.float32))  # Cast to float32
    intersection = sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (sum(y_true_f) + sum(y_pred_f) + smooth)

def dice_loss(y_true, y_pred):
    loss = 1 - dice_coeff(y_true, y_pred)
    return loss


def bce_dice_loss(y_true, y_pred):
    loss = 0.5 * binary_crossentropy(y_true, y_pred) + 0.5 * dice_loss(y_true, y_pred)
    return loss

def iou(y_true, y_pred):
    y_true_f = tf.cast(y_true, tf.float32)  # Cast to float32
    y_pred_f = tf.cast(tf.round(y_pred), tf.float32)  # Cast to float32 after rounding

    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) - intersection
    return intersection / (union + tf.keras.backend.epsilon())

def atrous_unet_model(input_size=(256, 256, 1)):
    inputs = Input(input_size)

    # Encoder
    c1 = Conv2D(16, (3, 3), dilation_rate=1, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(inputs)
    c1 = BatchNormalization()(c1)
    c1 = Activation('relu')(c1)
    c1 = Dropout(0.1)(c1)
    c1 = Conv2D(16, (3, 3), dilation_rate=1, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(c1)
    c1 = BatchNormalization()(c1)
    c1 = Activation('relu')(c1)
    c1 = Dropout(0.1)(c1)
    p1 = MaxPooling2D((2, 2))(c1)

    c2 = Conv2D(32, (3, 3), dilation_rate=2, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(p1)
    c2 = BatchNormalization()(c2)
    c2 = Activation('relu')(c2)
    c2 = Dropout(0.1)(c2)
    c2 = Conv2D(32, (3, 3), dilation_rate=2, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(c2)
    c2 = BatchNormalization()(c2)
    c2 = Activation('relu')(c2)
    c2 = Dropout(0.1)(c2)
    p2 = MaxPooling2D((2, 2))(c2)

    c3 = Conv2D(64, (3, 3), dilation_rate=4, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(p2)
    c3 = BatchNormalization()(c3)
    c3 = Activation('relu')(c3)
    c3 = Dropout(0.1)(c3)
    c3 = Conv2D(64, (3, 3), dilation_rate=4, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(c3)
    c3 = BatchNormalization()(c3)
    c3 = Activation('relu')(c3)
    c3 = Dropout(0.1)(c3)
    p3 = MaxPooling2D((2, 2))(c3)

    c4 = Conv2D(128, (3, 3), dilation_rate=8, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(p3)
    c4 = BatchNormalization()(c4)
    c4 = Activation('relu')(c4)
    c4 = Dropout(0.1)(c4)
    c4 = Conv2D(128, (3, 3), dilation_rate=8, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(c4)
    c4 = BatchNormalization()(c4)
    c4 = Activation('relu')(c4)
    c4 = Dropout(0.1)(c4)
    p4 = MaxPooling2D((2, 2))(c4)

    # Bottleneck
    c5 = Conv2D(256, (3, 3), dilation_rate=16, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(p4)
    c5 = BatchNormalization()(c5)
    c5 = Activation('relu')(c5)
    c5 = Dropout(0.1)(c5)
    c5 = Conv2D(256, (3, 3), dilation_rate=16, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(c5)
    c5 = BatchNormalization()(c5)
    c5 = Activation('relu')(c5)
    c5 = Dropout(0.1)(c5)

    # Decoder
    u6 = UpSampling2D((2, 2))(c5)
    u6 = concatenate([u6, c4])
    c6 = Conv2D(128, (3, 3), dilation_rate=8, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(u6)
    c6 = BatchNormalization()(c6)
    c6 = Activation('relu')(c6)
    c6 = Dropout(0.1)(c6)
    c6 = Conv2D(128, (3, 3), dilation_rate=8, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(c6)
    c6 = BatchNormalization()(c6)
    c6 = Activation('relu')(c6)
    c6 = Dropout(0.1)(c6)

    u7 = UpSampling2D((2, 2))(c6)
    u7 = concatenate([u7, c3])
    c7 = Conv2D(64, (3, 3), dilation_rate=4, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(u7)
    c7 = BatchNormalization()(c7)
    c7 = Activation('relu')(c7)
    c7 = Dropout(0.1)(c7)
    c7 = Conv2D(64, (3, 3), dilation_rate=4, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(c7)
    c7 = BatchNormalization()(c7)
    c7 = Activation('relu')(c7)
    c7 = Dropout(0.1)(c7)

    u8 = UpSampling2D((2, 2))(c7)
    u8 = concatenate([u8, c2])
    c8 = Conv2D(32, (3, 3), dilation_rate=2, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(u8)
    c8 = BatchNormalization()(c8)
    c8 = Activation('relu')(c8)
    c8 = Dropout(0.1)(c8)
    c8 = Conv2D(32, (3, 3), dilation_rate=2, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(c8)
    c8 = BatchNormalization()(c8)
    c8 = Activation('relu')(c8)
    c8 = Dropout(0.1)(c8)

    u9 = UpSampling2D((2, 2))(c8)
    u9 = concatenate([u9, c1])
    c9 = Conv2D(16, (3, 3), dilation_rate=1, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(u9)
    c9 = BatchNormalization()(c9)
    c9 = Activation('relu')(c9)
    c9 = Dropout(0.1)(c9)
    c9 = Conv2D(16, (3, 3), dilation_rate=1, kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(0.01))(c9)
    c9 = BatchNormalization()(c9)
    c9 = Activation('relu')(c9)
    c9 = Dropout(0.1)(c9)

    # Output layer
    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)

    model = Model(inputs=[inputs], outputs=[outputs])
    model.compile(optimizer=Adam(learning_rate=0.0005), loss=bce_dice_loss, metrics=['accuracy', dice_loss, iou, Precision, Recall, F1_score])

    return model

# Create the model
model = atrous_unet_model()
model.summary()

# Ανάγνωση των δεδομένων και επέκταση τους
infection_masks = np.concatenate(infection_mask, axis=0)
ct_scans = np.concatenate(ct_scan)

infection_mask_expand = np.expand_dims(infection_masks, axis=-1)
ct_scan_expand = np.expand_dims(ct_scans, axis=-1)
print(f"Μέγεθος του infection_mask: {infection_mask_expand.shape}")
print(f"Μέγεθος του ct_scan: {ct_scan_expand.shape}")

def display_black_images(images, mask):
    black_image_count = 0
    black_finder = []
    for i, image in enumerate(mask):
      if np.all(image == 0):  # Checks if all elements of the image are 0
        black_image_count += 1
        black_finder.append(i)  # Appending the index to the list

        # # Display the black image
        # plt.imshow(image.squeeze(), cmap='gray')  # Use squeeze to remove any singleton dimensions
        # plt.title(f'Black Image {i}')
        # plt.axis('off')
        # plt.show()

    images = np.delete(images, black_finder, axis=0)
    mask = np.delete(mask, black_finder, axis=0)

    print(f"Total black images: {black_image_count}")
    # To avoid the issue of deleting within the function that displays images,
    # you might want to return the indices to the caller for further processing.
    return images, mask

import numpy as np
import matplotlib.pyplot as plt
from imgaug import augmenters as iaa
from sklearn.model_selection import train_test_split

# Ορισμός του augmenter
seq = iaa.Sequential([
    iaa.Fliplr(0.5),
    iaa.Flipud(0.2),
    iaa.Affine(scale=(0.8, 1)),
    iaa.Affine(translate_percent={"x": (-0.2, 0.2), "y": (-0.2, 0.2)}),
    iaa.Affine(translate_px={"x": (-20, 20), "y": (-20, 20)}),
    iaa.Affine(rotate=(-30, 30))
    # iaa.Affine(shear=(-16, 16))
], random_order=True)

# Εφαρμογή deterministic augmentations
def augment_images_and_masks(images, masks):
    seq_det = seq.to_deterministic()  # Δημιουργεί ένα deterministic sequence
    augmented_images = seq_det(images=images)
    augmented_masks = seq_det(images=masks)
    return augmented_images, augmented_masks

# Εφαρμογή augmentation σε εικόνες και μάσκες
ct_scan_augmented, infection_mask_augmented = augment_images_and_masks(ct_scan_expand, infection_mask_expand)

ct_scan_augmented, infection_mask_augmented = display_black_images(ct_scan_augmented, infection_mask_augmented)

ct_scan_combined = np.concatenate([ct_scan_expand, ct_scan_augmented], axis=0)
infection_mask_combined = np.concatenate([infection_mask_expand, infection_mask_augmented], axis=0)

random_state = 0

# Διαχωρισμός σε σύνολα εκπαίδευσης και ελέγχου
X_train, X_test, y_train, y_test = train_test_split(ct_scan_combined, infection_mask_combined, test_size=0.2, random_state=random_state)

del infection_masks, ct_scans, infection_mask_expand, ct_scan_expand, ct_scan_augmented, infection_mask_augmented, ct_scan_combined, infection_mask_combined
gc.collect()

# # %%%%%%%%%%%%%%%%%%%%%%%%% PLOT %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# # Συνάρτηση για εμφάνιση εικόνας με τη μάσκα πάνω της με opacity
# def show_image_with_mask(image, mask, alpha=0.5):
#   # Display image with mask overlay with reduced opacity
#   overlay = image.squeeze().copy()
#   mask_overlay = np.zeros_like(overlay)
#   mask_overlay[mask.squeeze() > 0] = 1  # Create a binary mask for the overlay

#   plt.imshow(overlay, cmap='gray')
#   plt.imshow(mask_overlay, cmap='jet', alpha=alpha)  # squeeze για να αφαιρέσουμε τη διάσταση του καναλιού
#   plt.axis('off')
#   plt.show()



# # Εμφάνιση παραδειγμάτων εικόνων με τις μάσκες
# for i in range(10):  # Εμφάνιση 3 παραδειγμάτων από το X_train
#     show_image_with_mask(X_train[i], y_train[i])

# Function to plot metrics
# Function to plot metrics with best epoch marker
def plot_metrics(history, metrics=('accuracy', 'dice_loss', 'iou', 'loss')):
    # Number of metrics to plot
    num_metrics = len(metrics)

    # Create subplots
    fig, axes = plt.subplots(1, num_metrics, figsize=(20, 5))

    # Loop through each metric
    for i, metric in enumerate(metrics):
        # Extract the metric values for training and validation
        train_values = history.history[metric]
        val_values = history.history[f'val_{metric}']

        # Identify the best epoch index
        if 'loss' in metric:
            best_idx = np.argmin(val_values)  # Best is minimum for loss
        else:
            best_idx = np.argmax(val_values)  # Best is maximum for other metrics

        # Plot the values
        axes[i].plot(train_values, label=f'Train {metric}')
        axes[i].plot(val_values, label=f'Validation {metric}')
        # Add a marker for the best epoch
        axes[i].plot(best_idx, val_values[best_idx], 'bo')  # 'bo' -> blue circle marker
        axes[i].annotate(f'Best Epoch: {best_idx+1}', (best_idx, val_values[best_idx]),
                         textcoords="offset points", xytext=(0,10), ha='center')

        # Set the title and labels
        axes[i].set_title(f'Training and Validation {metric}')
        axes[i].set_xlabel('Epochs')
        axes[i].set_ylabel(metric.capitalize())
        axes[i].legend()

    # Adjust layout
    plt.tight_layout()
    plt.show()

def plot_comparison(images, true_masks, pred_masks, num_samples=3):
    fig, axes = plt.subplots(num_samples, 4, figsize=(20, 10))
    axes = axes.flatten()

    for i in range(num_samples):
        # Display CT scan
        ax = axes[i * 4]
        ax.imshow(images[i, :, :, 0], cmap='gray')
        ax.axis('off')
        ax.set_title('CT Scan')

        # Display True Mask
        ax = axes[i * 4 + 1]
        ax.imshow(images[i, :, :, 0], cmap='gray')
        ax.imshow(true_masks[i, :, :, 0], cmap='jet', alpha=0.5)
        ax.axis('off')
        ax.set_title('True Mask')

        # Display Predicted Mask
        ax = axes[i * 4 + 2]
        ax.imshow(images[i, :, :, 0], cmap='gray')
        ax.imshow(pred_masks[i, :, :, 0], cmap='jet', alpha=0.5)
        ax.axis('off')
        ax.set_title('Predicted Mask')

        # Overlay True Mask and Predicted Mask
        ax = axes[i * 4 + 3]
        ax.imshow(images[i, :, :, 0], cmap='gray')
        ax.imshow(true_masks[i, :, :, 0], cmap='Greens', alpha=0.5)  # True mask in green
        ax.imshow(pred_masks[i, :, :, 0], cmap='Reds', alpha=0.5)  # Predicted mask in red
        ax.axis('off')
        ax.set_title('Overlay Comparison')

    plt.tight_layout()
    plt.show()

from sklearn.model_selection import KFold, train_test_split
from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, accuracy_score
import time
import gc


n_splits = 3

kf = KFold(n_splits=n_splits, shuffle=True, random_state = random_state)
results = []
for fold_number, (train_index, val_index) in enumerate(kf.split(X_train)):

  start_time = time.time()
  X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]
  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]

# &&&&&&&&&&&&&&&&&&&&&& FOR IMAGE AUGMEDATION WITH albumentationImageDataGenerator &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
  # # Initialize data generators for the current fold
  # train_generator = AlbumentationsImageDataGenerator(
  #     images=X_train_fold,
  #     masks=y_train_fold,
  #     batch_size=8,
  #     augmentations=augmentations
  # )

  # val_generator = AlbumentationsImageDataGenerator(
  #     images=X_val_fold,
  #     masks=y_val_fold,
  #     batch_size=8,
  #     augmentations=augmentations  # Optional: You might want less/no augmentation for validation data
  # )
# &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

# &&&&&&&&&&&&&&&&&&&&&& FOR IMAGE AUGMEDATION WITH albumentationImageDataGenerator &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
  # # Initialize data generators for the current fold
  # train_generator = AlbumentationsImageDataGenerator(
  #     images=X_train_fold,
  #     masks=y_train_fold,
  #     batch_size=8,
  #     augmentations=augmentations
  # )

  # val_generator = AlbumentationsImageDataGenerator(
  #     images=X_val_fold,
  #     masks=y_val_fold,
  #     batch_size=8,
  #     augmentations=augmentations  # Optional: You might want less/no augmentation for validation data
  # )
# &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&


# &&&&&&&&&&&&&&&&&&&&&& FOR TYPICAL IMAGE AUGMEDATION  &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

  # # Fit the data generators to the training data για κάθε fold
  # image_datagen.fit(X_train_fold, augment=True, seed=random_state)
  # mask_datagen.fit(y_train_fold, augment=True, seed=random_state)

  # # Create generators for training για κάθε fold
  # train_image_generator = image_datagen.flow(X_train_fold, batch_size=8, seed=42)
  # train_mask_generator = mask_datagen.flow(y_train_fold, batch_size=8, seed=42)
  # val_image_generator = image_datagen.flow(X_val_fold, batch_size=8, seed=42)
  # val_mask_generator = mask_datagen.flow(y_val_fold, batch_size=8, seed=42)

  # train_generator = combine_generators(train_image_generator, train_mask_generator)
  # val_generator = combine_generators(val_image_generator, val_mask_generator)

  # steps_per_epoch = len(X_train_fold) // 8  # Assuming batch size of 8
  # validation_steps = len(X_val_fold) // 8   # Assuming batch size of 8

# &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

  # Create the model
  model = atrous_unet_model()
  model.compile(optimizer=Adam(learning_rate=0.0005), loss=bce_dice_loss, metrics=['accuracy', dice_loss, iou, Precision, Recall, F1_score])

  import tensorflow as tf
  from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger
  # Model Checkpoint: αποθήκευση του καλύτερου μοντέλου με βάση το validation loss
  # checkpoint = ModelCheckpoint('best_atrous_unet_model.keras', monitor='val_loss', save_best_only=True, verbose=1)
  checkpoint = ModelCheckpoint(f'best_atrous_unet_model_fold{fold_number}.keras', monitor='val_loss', save_best_only=True, verbose=1)

  # Early Stopping: σταματάει την εκπαίδευση αν δεν υπάρχει βελτίωση στο validation loss
  early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)

  # ReduceLROnPlateau: μειώνει το learning rate αν το validation loss δεν βελτιώνεται για κάποιο διάστημα
  reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6, verbose=1)

  # CSV Logger: καταγραφή των μετρικών σε αρχείο CSV
  csv_logger = CSVLogger('training_log.csv', append=True)

  # Λίστα Callbacks
  callbacks = [reduce_lr, early_stopping, checkpoint, csv_logger]

  # Model training
  # history = model.fit(
  #   train_generator,
  #   validation_data=val_generator,
  #   epochs=50,
  #   callbacks=callbacks,
  #   steps_per_epoch=steps_per_epoch,
  #   validation_steps=validation_steps
  # )

  history = model.fit(
      X_train_fold, y_train_fold,
      validation_data=(X_val_fold, y_val_fold),
      epochs=60,
      batch_size=16,
      callbacks=callbacks
  )

   # Evaluate on the test set
  test_scores = model.evaluate(X_test, y_test, verbose=0)

  # Time duration
  duration = time.time() - start_time

  # Append results for each set
  metrics_to_include = ['loss', 'accuracy', 'dice_loss', 'iou', 'precision', 'recall', 'f1_score']
  for set_name, metric_values in zip(['Train', 'Validation', 'Test'],
                                      [history.history, history.history, test_scores]):
      set_results = {
          'Fold': fold_number + 1,
          'Model': 'Atrous U-Net',
          'Set': set_name,
          'Duration': duration
      }
      for metric in metrics_to_include:
          if set_name == 'Test':
              set_results[metric] = metric_values[metrics_to_include.index(metric)]
          else:
              set_results[metric] = metric_values[f'{metric}'][-1] if set_name == 'Train' else metric_values[f'val_{metric}'][-1]

      results.append(set_results)

  # Call the function to plot the metrics
  plot_metrics(history, metrics=['accuracy', 'dice_loss', 'iou', 'loss'])

  # Assuming X_val_fold and y_val_fold are your validation images and true masks
  predictions = model.predict(X_val_fold)
  predicted_masks = (predictions > 0.5).astype(np.uint8)  # Threshold predictions to create binary mask

  # Choose how many samples you want to display
  num_samples_to_display = 5  # Adjust based on how many you want to see
  plot_comparison(X_val_fold, y_val_fold, predicted_masks, num_samples=num_samples_to_display)


  # Clear resources
  del model, history, X_train_fold, X_val_fold, y_train_fold, y_val_fold
  gc.collect()

# Convert results to DataFrame and save to Excel
results_df = pd.DataFrame(results)
results_df.to_excel('Atrous 0.xlsx', index=False)

# prompt: download excel

from google.colab import files
files.download('Atrous 0.xlsx')